---
title: "Toy example of a coreference analysis in rezonateR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Toy example of a coreference analysis in rezonateR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE
)
options(rmarkdown.html_vignette.check_title = FALSE)
library(dplyr)
```


```{r, eval = FALSE}
install.packages("devtools")
library(devtools)
install_github("rezonators/rezonateR")
```


The aim of this article is to demonstrate, using a sample, highly simplified project, what type of analysis may be conducted using Rezonator and `rezonateR`. This particular example will examine the choice of referential forms in spoken dialogue: What factors lead to the choice of a longer form (e.g. *the three black cats*) versus a shorter one (e.g. *them*)?

The data here is the same as that used in the series of tutorials starting with `vignette("import_save_basics")`, but this article will have less focus on how to write the code, and more on showing you how to answer the sample research question using `rezonateR`.

This article does not assume that you have read any of the other articles on `rezonateR`. So there is some overlap in the topics covered. I will point you to other tutorials for further details when necessary.

You are welcome to follow this tutorial in R. If you are reading this in R using the file `sample_proj.Rmd`, you can simply click on the 'run' button (green 'play' icon on the top right of each box). As long as all the code blocks are run sequentially, the code should work; otherwise, open a ticket on GitHub!

## The research question

It is often noted that in language, if a referent is more â€˜accessible', or more easily accessed mentally - for example, it is salient in the previous discourse or physical context - then we will tend to refer to it using a shorter and simpler form form. Things that are less accessible - for example, things that are mentioned for the first time - tend to be referred to using longer forms. Thus, we should expect that in natural discourse, factors that render a referent more accessible are associated with shorter forms, and factors that make it less accessible are associated with longer forms.

But what makes something more accessible, and therefore more likely to be referred to using a shorter form? The best way to investigate this question is to propose some factors that may increase accessibility, and then determine whether they are associated with the use of a shorter form in natural discourse. This project is a preliminary investgation of this issue using a snippet of conversation.

## The input data from Rezonator
The data used in this example is from the text *A Tree's Life*, a conversation between two sisters from the Santa Barbara Corpus of Spoken American English. The first 162 lines have been annotated here, which deals with the topic of one of the sisters' roommates.

The file has been annotated for coreference (trails), resonance, as well as argument structure (through trees). For this tutorial, resonance will be ignored. Coreference chains include referential expressions along with non-referring expressions that have been otherwise referred back to (e.g. discourse deixis). Figure 1 shows an example of the data  in the Rezonator interface:

![Figure 1](img/sample_sbc007.PNG){width=100%}

Wavy lines indicate coreference links. Each mention or referential expression is a *track* inside the larger trail.   These expressions all form tracks that are part of the trail for Mary:

![Figure 2](img/sample_track.PNG){width=100%}

In this file, entire clauses that serve as antecedents in cases of discourse deixis are also considered tracks. For example, notice that the two occurrences of *I* on Line 2 are linked together with a purple link, along with the zero on line 3.

Two-layered trees indicate argument structure of each verb. The verbal complex (including auxiliaries and adverbs that intervene between the auxiliary and verb, but not arguments that intervene between auxiliary and verb) is annotated as blank chunks (with chunkType = "verb") and serves as the root of each tree. Tree links are annotated as Relation = "Subject" when it indicates a subject-verb relation; otherwise Relation is left blank. For example, the tree panel of Figure 3 shows the argument structure of Line 4, with *defeats* as the root with three children: a zero subject, the object *the purpose of getting up in the morning*, and the adverb *kinda*:

![Figure 3](img/sample_tree.PNG){width=100%}


There are two types of chunks (elements represented by rectangles) in this file: Chunks that have been created as part of a trail (mostly referential expressions - such as *the purpose of getting up in the morning* the example), and verbs, which are 'blank chunks', i.e. do not belong to any trail and appear with grey borders (such as *said* in the example). Chunks have been annotated for two properties: `chunkType` (which is `verb` for verbs and left blank for referential expressions) and `largerChunk`, i.e. the larger chunk to which a chunk belongs. Note that `number` is NOT annotated; it will instead be annotated with the help of `rezonateR`.

![Figure 4](img/sample_chunk.PNG){width=100%}

## Our goal in rezonateR
As we said above, our goal is to determine whether several factors that are proposed to be relevant to accessibility are associated with shorter referential forms.

To this end, we will be buildiong a model that predicts the `charCount`, i.e. length (in number of characters) of a certain referential expression. Several predictors will be used to predict `charCount` in our small dataset. Here is a spoiler of the final set of factors:

* `noPrevSubjMentionsIn10`: The number of coreferent subject mentions within the 10 previous intonation units. That is, how many times was the referent of a form mentioned in the 10 previous intonation units in subject position?
* `noPrevNonSubjMentionsIn10`: The number of coreferent non-subject mentions within the 10 previous units. That is, how many times was the referent of a form mentioned in the 10 previous intonation units, outside of subject position?
* `gapUnits`: How many units are there between the previous mention and the current one?
* `noCompetitors`: The number of competitors within the five previous units. That is, how many times were entities other than the referent of the current referential expression mentioned within the five previous intonation units?
* `Relation`: Is the current referential expression a subject? 
* `isPredOrFree`: Is the current mention either a nominal predicate (copula complement) or not tied to a particular clause?
* `number`: Is the current referential expression singular or plural?

Thus, our goal within R is to create a data frame where each row corresponds to a referential expresssion, and the columns include all of these factors (plus `charCount`, the number of characters). This can be done easily using the `rezonateR` functions after inputting the raw Rezonator data.

## Importing the file

The first step is to import the file. When importing a file, an object called `rezrObj` is created. `rezrObj` contains two kinds of elements:

* A `nodeMap`, which contains the data in the form of a series of interconnected nodes with attributes
* A series of `rezrDF`s, which are data frames containing information about different elements of the file.

Some important `rezrDF`s include: `tokenDF`, which contains the information about individual tokens of the original file, `chunkDF`, which contains information about chunks, `trackDF`, which contains information about entries of trails (i.e. mentions in coreference chains), and `treeEntryDF`, which contains information about entries on a tree.

Here's the import code. It contains two kinds of information: 

* How to divide the chunks into layers. Here, we divide the chunks into two layers, `verb` and `refexpr` (for 'referential expressions', including the entire clauses we've seen before). Chunks in the two layers are put into two separate `rezrDF`s. Since no layers are specified for `trackDF` and `treeDF`, there will be only one `rezrDF` for them, with the layer name `default`.
* Which fields of a token contains text to be concatenated in `concatFields`. The fields `text` and `transcript` of the Santa Barbara Corpus are concatenated to form `text` and `transcript` fields of larger structures like units and chunks. Telling this information to `rezonateR` is important for the text to appear in tables like `chunkDF` or `unitDF`.

```{r}
library(rezonateR)
path = system.file("extdata", "sbc007.rez", package = "rezonateR", mustWork = T)

layerRegex = list(chunk = list(field = "chunkType",
                               regex = c("verb"),
                               names = c("verb", "refexpr")))
concatFields = c("text", "transcript")
rez007 = importRez(path,
                   layerRegex = layerRegex,
                   concatFields = concatFields)
```

As examples of the content inside the imported object, here are the imported `chunkDF` members and `trackDF`:

```{r}
head(rez007$chunkDF)
head(rez007$trackDF$default)
```

More information about the import process and the various objects created can be found in `vignette("import_save_basics")`.

Each line of the table `rez007$trackDF$default` contains a referential expression whose size we want to predict. The goal of using `rezonateR` for this project will be to produce a version of the data frame `rez007$trackDF` that contains all the predictors and the dependent variable on each line, and may be fed to models such as `lm()`.

You can save the `rezrObj` with `rez_save()` so that it can be opened with `rez_load()` next time, saving you the trouble of importing again:

```{r}
savePath = "rez007.Rdata"
rez_save(rez007, savePath)
```


## Augmenting the file with basic information about order and sequence

After importing the file, there are a few simple operations that we usually call to add additional information to the table which was not added during the original import process, before beginning the process of editing.

### Words vs tokens

By default Rezonator  provides two fields related to the position of a token, which you will see in `tokenDF` as columns:

* `docTokenSeq` - refers to the order of a token within the entire text
* `tokenOrder` -  refers to the position of a token within its intonation unit

Structures that span multiple tokens, like chunks and units, have four token sequence-related fields:

* `docTokenSeqFirst` - refers to the `docTokenSeq` of the first token.
* `docTokenSeqLast` - refers to the `docTokenSeq` of the last token.
* `tokenOrderFirst` - refers to the `tokenOrder` of the first token.
* `tokenOrderLast` - refers to the `tokenOrder` of the last token.

Here are some examples:

```{r}
head(rez007$tokenDF %>% select(id, text, tokenOrder, docTokenSeq))
head(rez007$chunkDF$refexpr %>% select(id, text, tokenOrderFirst, tokenOrderLast,  docTokenSeqFirst, docTokenSeqLast))
```

These values count all tokens in the file. In the Santa Barbara Corpus text we are using, this includes endnotes (such as `,` and `.`), transcriptions of vocalisms (such as `(H)` for in-breaths and `@@@` for laughter), and so on. What if we want a version of fields like `tokenOrder` and `docTokenSeq` that excludes these, including just 'real' words like *person* and *love*? We can use the function `addIsWordField()`:

```{r, cache = TRUE}
rez007 = addIsWordField(rez007, kind == "Word")
```

This adds the fields `wordOrder` and `docWordSeq` to `tokenDF` (and also its counterparts in places like `chunkDF` and `unitDF`, e.g. `wordOrderFirst`, `wordOrderLast`, `docWordSeqFirst`, `docWordSeqLast`). These new fields discount non-real words, which get the value `0`. Here's an example in `tokenDF`:

```{r}
head(rez007$tokenDF %>% select(id, tokenOrder, docTokenSeq, wordOrder, docWordSeq))
```

### Unit sequence information

Information about the location of elements other than tokens inside units is not included by default. The function `addUnitSeq()` does this. Here, `unitSeqFirst` and `unitSeqLast` are added to `chunkDF` and `trackDF`, allowing us to see which units chunks and tracks belong to:

```{r}
rez007 = addUnitSeq(rez007, "track")
head(rez007$chunkDF$refexpr %>% select(id, text, unitSeqFirst, unitSeqLast))
```

For the details of these functions, see `vignette("time_seq")`.

## Pass 1: Predicting length from lookback distance

### `gapUnits`: Lookback distance in R

As you may have noticed when using Rezonator, Rezonator automatically calculates the number of distances from each track (mention) to the previous mention in the same trail (coreference chain). This is called `gapUnits`, and it is automatically imported from Rezonator into rezonateR in `trackDF`. The `gapUnits` value is `N/A` for first mentions of things; otherwise it is a nonnegative integer.

Because first mentions are usually not accessible in discourse when they are first introduced, we can expect that they would be referred to using heavier noun phrases. Let's try to verify that this is the case. (This tutorial will use some Tidyverse functions, such as those from `ggplot2`; feel free to click on any functions that you do not recognise to see their documentation).

```{r}
library(ggplot2)
rez007$trackDF$default %>%
  mutate(isFirst = case_when(gapUnits == "N/A" ~ "First",
                             T ~ "NonFirst")) %>%
  ggplot(aes(x = isFirst, y = charCount)) + geom_violin()
```


Clearly, we can see that first mentions have a much higher tendency to be referred to using a noun phrase that has more characters.

Among the non-first mentions, can we also predict whether the character count from `gapUnits`? Let's again do a quick visualisation. If we exclude non-first mentions, and plot the relationship betwee `gapUnits` and `charCount`, this is what we get:

```{r}
rez007$trackDF$default %>%
  filter(gapUnits != "N/A", charCount > 0) %>%
  mutate(gapUnits = as.integer(gapUnits)) %>%
  ggplot(aes(x = gapUnits, y = charCount)) + geom_count()
```

Oh no, what's going on? It seems that `gapUnits` is not predicting what we would usually expect to see. Most of the long `gapUnits` noun phrases are fairly light, and there are quite a few small `gapUnits` phrases that are quite long.

In the rest of the tutorial, we will partially account for this weirdness (though some of it is certainly due to our small, biased dataset). But for now, let's try to apply a simple linear model to this data to see what happens when we try to predict `charCount` from `gapUnits`. (Note: This is not the best model for the model specification we're looking at, but let's keep it simple for this tutorial.)

```{r}
pass1_model1 = rez007$trackDF$default %>%
  filter(gapUnits != "N/A", charCount > 0) %>%
  mutate(gapUnits = as.integer(gapUnits)) %>%
  lm(charCount ~ gapUnits, .)
summary(pass1_model1)
```
As we can see, although there is a negative coefficient that says a larger `gapUnits` leads to a smaller character count (as expected), it is not significant.

### A finer-grained distance metric?

There is another value, `gapWords`, that is automatically calculated in Rezonator and calculates the number of tokens from the current mention to the previous one. Would this finer-grained measure do better than `gapUnits`? Let's try:


```{r}
rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  mutate(gapWords = as.integer(gapWords)) %>%
  ggplot(aes(x = gapWords, y = charCount)) + geom_count()
pass1_model2 = rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  mutate(gapWords = as.integer(gapWords)) %>%
  lm(charCount ~ gapWords, .)
summary(pass1_model2)
```

The pattern is not much clearer from the diagram this time than last time, and there is little change with the linear model either: The p-value is still around 0.2.

There are ways we can potentially improve on these measures as well as other predictors of character count that we can potentially explore. We'll continue doing this throughout the tutorial.


## Pass 2: Adding predictors with EasyTrack 

Having attempted to predict character count from predictors imported directly from Rezonator, let's try to derive some predictors using `rezonateR` functions. This section will cover some basic functions in the `EasyTrack` series of functions. See `vignette("track")` for details about them.

### Counting previous mentions
The function `countPrevMentions()` in `rezonateR` is one function we can use. In its simplest form, you can simply specify a window of units in which to look for referential expressions that corefer with the each mention. We will look at the 10 previous units. We will add this value to the `trackDF` using the `rez_mutate()` function, which is part of the TidyRez family (`vignette("edit_tidyRez")`). (We use this function rather than `dplyr::mutate()` in order to ensure that the resulting data frame will remain in the correct `rezonateR` format.) Here is the code, along with a line of code that displays the first couple of values of this predictor:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_mutate(noPrevMentionsIn10 = countPrevMentions(10))
rez007$trackDF$default %>% select(id, text, noPrevMentionsIn10)  %>% slice(1:20)
```
Now let's try to draw a scatterplot and fit a linear model plotting this predictor against `charCount`, as we have done before:

```{r}
rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  ggplot(aes(x = noPrevMentionsIn10, y = charCount)) + geom_count()
pass2_model1 = rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  lm(charCount ~ noPrevMentionsIn10, .)
summary(pass2_model1)
```

From the graph, we see that there *is* a tendency for character counts to be smaller when the number of previous mentions is greater, albeit somewhat weak. The very large referential expressions are absent when there are more than 5 previous mentions, and after about five mentions, we can see the modal character length decreasing as well. From the linear model, We also find that the number of previous mentions in the previous 10 units *is* a significant predictor at the 0.05 significance level.

### Counting competitors

The function `countCompetitors()` is similar to `countPreviousMentions()`, except that it counts the number of referential expressions that are *not* in the same coreference chain, i.e. compete for the interlocutors' attention. The syntax is similar to `countPreviousMentions()`, with the extra argument `between`, which specifies whether you want to count only expressions between the current mention and the previous one. We will add this value to the `trackDF` using the `rez_mutate()` function again. So let's try to add the number of competitors now:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_mutate(noCompetitors = countCompetitors(windowSize = 10, between = F))
rez007$trackDF$default %>% select(id, noCompetitors)  %>% slice(1:20)
```

Now let's try to draw a scatterplot and fit a linear model, as we have done before:

```{r}
rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  ggplot(aes(x = noCompetitors, y = charCount)) + geom_count()
pass2_model1 = rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  lm(charCount ~ noCompetitors, .)
summary(pass2_model1)
```

From the graph, there does seem to be a small effect where a greater number of competitors leads to the use of fewer characters. This effect again turns out to be significant at the 0.05 significance level.

However, there is good reason to believe that `noCompetitors` and `noPrevMentionsIn10` may be highly correlated, and thus some of the effect we see for `noCompetitors` may actually due to the presence of previous mentions, or vice versa. This is because of there are more non-coreferring expressions in the previous units, there will tend to be fewer coreferring expressions, assuming that the number of referential expressions is relatively stable, i.e. our two competitors are negatively correlated are negatively correlated. The code below plots them in a graph and calculates the Pearson correlation coefficient, which is somewhat negative:

```{r}
rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  ggplot(aes(x = noCompetitors, y = noPrevMentionsIn10)) + geom_count()
cor(rez007$trackDF$default$noCompetitors, rez007$trackDF$default$noPrevMentionsIn10)
```

So let's try to put both in the model and how the results turn out:

```{r}
pass2_model3 = rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  lm(charCount ~ noCompetitors + noPrevMentionsIn10, .)
summary(pass2_model3)
```
As we can see, once we put both in the model, `noCompetitors` becomes the only significant predictor. (Of course, this does not mean that `noPrevMentionsIn10` does not matter; we only have very low power, after all.)

As a last attempt, let's also try the lookback-based approach by adding `gapUnits` to the model as well:

```{r}
pass2_model4 = rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  mutate(gapUnits = as.numeric(gapUnits)) %>%
  lm(charCount ~ noCompetitors + noPrevMentionsIn10 + gapUnits, .)
summary(pass2_model4)
```

Interestingly, this time, *all three* predictors turn out to be significant. The first two are in expected directions: having more competitors leads to longer referential expressions, whereas more recent mentions makes the form smaller. However, the `gapUnits` effect is in the opposite direction as we expect: The greater the gap, the smaller the referential expression! This does not appear to make sense. We will continue to improve this model in the following sections to see what happens to `gapUnits`.

### Upgrading `gapWords`

There's an additional thing we could do. The `gapWords` in Rezonator actually has a couple of problems; namely, it treats zeroes as belonging to the position you put the `<0>` in (which is arbitrary), and it counts non-words such as pauses, breaths or laughter, which you might not want to count. Let's try to use the `rezonateR` function `tokensToLastMention()` instead to deal with these issues. We can treat `<0>` as belonging to the end of the intonation unit they are annotated at, and define `docWordSeqLast` as the token sequence used in calculation, thus discounting non-words:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_mutate(gapWordsNew = tokensToLastMention(tokenOrder = docWordSeqLast,
                                               unitDF = rez007$unitDF,
                                               zeroProtocol = "unitFinal",
                                               zeroCond = (text == "<0>")))
```

Now we can put this new `gapWords` into the model:

```{r}
pass2_model5 = rez007$trackDF$default %>%
  filter(gapWords != "N/A", charCount > 0) %>%
  mutate(gapUnits = as.numeric(gapUnits)) %>%
  lm(charCount ~ noCompetitors + noPrevMentionsIn10 + gapWordsNew, .)
summary(pass2_model5)
```
This has no significant effect, and indeed takes away the significance of `noPrevMentionsIn10` too.

## Pass 3: Full analysis

### Merging chunks

You have likely suspected by now that there is something wrong with our `gapUnits` measure. And you would be correct! There *is* a mistake in how we have been approaching these calculations.

Let's look at some cases where `gapUnits` is very small, but `charCount` is mysteriously very large, and see what's wrong with them. We'll set the cutoff for `gapUnits` at 1, and the cutoff for `charCount` at 20.

```{r}
rez007$trackDF$default %>% filter(gapUnits <= 1, charCount > 20)
```

Notice that some of these do not seem to be actual referential expressions. Some of these are legitimate; for example, *nobody fucks with my lifestyle* happens to have been referred to by a cataphorical *it*:

![Figure 5](img/sample_fucks.PNG)

However, *(...) in self assertiveness ,* is an error. The problem is that in Rezonator, it is not possible to create chunks that span multiple units. We can only create individual chunks for each unit. So in this screenshot, *a real good lesson for them ,*, *too ,*, and *(...) in self assertiveness ,* are three separate chunks, when they should really only be a single chunk:

![Figure 6](img/sample_multiline.PNG)

This created a situation where *(...) in self assertiveness* is mistakenly taken as long referential expression that occurred right after a previous mention *too ,*.

`rezonateR` is equipped with the ability to combine several chunks inside the file into one larger chunk. Before we do this, though, we need to spice up our data frames with information from the trees, which will provide us with some of the information helpful for merging chunks together. This will also be helpful for other types of operations later on too, so let's take a look at this feature.

#### Adding tree information

Inside Rezonator, there are no direct links between trees and entities like tracks and chunks. The function `getAllTreeCorrespondences()` adds a column `treeEntry` to various tables, which gives the ID of the corresponding entry in the table `treeEntryDF`:

```{r}
rez007 = getAllTreeCorrespondences(rez007, entity = "track")
head(rez007$tokenDF %>% select(id, text, treeEntry))
head(rez007$chunkDF$refexpr %>% select(id, text, treeEntry))
head(rez007$trackDF$default %>% select(id, text, treeEntry))
```

This will be useful later on for other things as well, not just for merging chunks.

#### `mergeChunksWithTree()` and `mergeChunksWithIDs()`
There are two functions for merging chunks in `rezonateR`:

* `mergeChunksWithTree()`: If there is a treeEntry that corresponds to the concatenation of multiple chunks, then we merge those chunks.
* `mergeChunksWithIDs()`: We merge chunks by assigning IDs to individual chunks that indicate the merged chunk it is supposed to belong to. In this dataset, this is done in the field `largerChunk` on chunks. For example, the first chunk you create this way may have the ID 1, the second chunk 2, the third chunk 3 and so on. In this case, all the component chunks of the first complex chunk should have the value `1` for `largerChunk` and so on.

The new chunks will be added to the bottom of `chunkDF`. In addition, `chunkDF` will have an extra column `combinedChunk` giving information about chunk combinations:

```{r}
rez007 = mergeChunksWithTree(rez007)
rez007 = mergeChunksWithIDs(rez007, "largerChunk")
#Show combined referential expressions
rez007$chunkDF$refexpr %>%
  filter(combinedChunk != "") %>%
  select(id, text, combinedChunk) #Showing only combined chunks and their members
```

`mergedChunksToTrack()` puts this information in the `trackDF` too:

```{r}
rez007 = mergedChunksToTrack(rez007, "default")
#Show combined track members
rez007$trackDF$default %>%
  filter(combinedChunk != "") %>%
  select(id, name, text, combinedChunk) #Showing only combined chunks and their members
```

Using magic, `rezonateR` automatically calculates the values of fields like `noCompetitors` when you combine chunks, so you don't need to worry about recalculating anything for the merged chunks.

### `gapUnits`, take two

Now that we have merged some of these chunks, it's time to redo the `gapUnits` value. We can do this by using the `unitsToLastMention()` function, and setting the value of `exclFrag` to `TRUE` (i.e. excluding fragments of chunks) and `nonFragmentMember` to the rows that do not have the string `"member"` in `combinedChunk`:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_mutate(gapUnitsNew = unitsToLastMention(exclFrag = T,
                                               nonFragmentMember = !str_detect(combinedChunk, "member")))
```

This new value `gapUnitsNew` has an `NA` value for fragments of chunks, and also ignores them when calculating `gapUnits`. Let's try to plot the relationship between `gapUnitsNew` and `charCount` again:

```{r}
rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew)) %>%
  mutate(gapUnitsNew = as.integer(gapUnitsNew)) %>%
  ggplot(aes(x = gapUnitsNew, y = charCount)) + geom_count()
```

While we still can't see the expected effect, some of the outliers on the top left of the graph are now gone.

The `noPrevMentionsIn10` and `noCompetitors` columns can also be redone to ignore fragments:

```{r}

rez007$trackDF$default = rez007$trackDF$default %>%
    rez_mutate(noPrevMentionsIn10 = countPrevMentions(10,
                                    exclFrag = T,
                                    nonFragmentMember = !str_detect(combinedChunk, "member")))
rez007$trackDF$default = rez007$trackDF$default %>%
    rez_mutate(noCompetitors = countCompetitors(windowSize = 10, between = F,
                                                exclFrag = T,
                                               nonFragmentMember = !str_detect(combinedChunk, "member")))
```

Now with the corrected data, let's try to refit the linear model:

```{r}
pass3_model1 = rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew), charCount > 0) %>%
  lm(charCount ~ noCompetitors + noPrevMentionsIn10 + gapUnitsNew, .)
summary(pass3_model1)
```
This time, `noCompetitors` is no longer a good predictor. The coefficient of `gapUnitsNew` is still in the 'wrong' direction, since a larger `gapUnitsNew` still leads to a smaller referential expression, but the effect is not significant any more.

Is there any way we can improve on this model a little more? Let's consider the cases with small `gapUnits` but large character counts again. It turns out that many of them are **predicates** of copular clauses, like the following example, which has the very long expression *what I'm gonna tell  him* coreferential to the subject *that*:

![Figure 7](img/sample_pred.PNG)

On the other hand, very few of these are subjects. This suggests that it will be useful to add information about grammatical relations. Subjects are likely to be biased towards shorter character counts, and predicates towards longer ones. The two following sections will add these elements. First we will add the `Relation` predictor, which is annotated in the data and tells whether a referential expression is the subject of a clause. Then we write code to automatically guess whether something is a predicate.

### Adding information about verbs and argument structure

Now let's add the `Relation` variable, which determines whether a certain referential expression is the subject of a verb, a factor frequently argued to be increasing accessibility. We use `addFieldForeign()`, which belongs to the EasyEdit family of functions covered in `vignette("edit_easyEdit")`. Recall that we've put a `treeEntry` column in `trackDF` that gives the ID of the corresponding tree entry. The following code looks into `treeEntryDF`, finds the `Relation` value corresponding to a `treeEntry`, and adds it to `trackDF`, allowing us to know whether each referential expression is a subject:

```{r}
rez007 = rez007 %>%
  addFieldForeign("track", "default", "treeEntry", "default", "treeEntry", "Relation", "Relation", fieldaccess = "foreign")
head(rez007$track$default %>% select(id, chain, text, treeEntry, Relation))
```

We can also replace the `NA` values in `Relation` by `"NonSubj"`, and turn it into a factor with `stringToFactor()` so that it can be used in modelling:

```{r, message=FALSE}
rez007$trackDF$default = rez007$trackDF$default %>% 
  rez_mutate(Relation = coalesce(Relation, "NonSubj"), fieldaccess = "flex") %>%
  stringToFactor(c("Relation"))
```

We can now plot the `charCount` values of subjects and non-subjects:

```{r}
rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew)) %>%
  ggplot(aes(x = Relation, y = charCount)) + geom_violin()
```


The pattern overwhelmingly supports our hypothesis. Now let's see what `Relation` turns up if we put it in the linear model:

```{r}
pass3_model2 = rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew), charCount > 0) %>%
  lm(charCount ~ noCompetitors + noPrevMentionsIn10 + gapUnitsNew + Relation, .)
summary(pass3_model2)
```
As we can see, subjects are likely to be far shorter than non-subjects. The effects of the other factors are gone in this model.


### Adding the effect of predicatehood

We can now add a variable to pick out predicates. There's a quick and dirty way to guess which referential expressions are predicates: We can pick out those expressions that are arguments of copulas, i.e. have a copula in the column `verbText`, and also are not subjects. This will incorrectly pick out adjuncts of copula clauses, but those are infrequent enough in our sample that we can get away with it.

In addition, referential expressions that don't belong to any verb are often also predicate-like in behaviour, such as the multiline chunk we've seen before:

![Figure 8](img/sample_multiline.PNG)

So we can also include them as 'predicates' as good measure. Let's call the resulting column `isPredOrFree`, with 'free' meaning 'free from a verb'. (Note that this incorrectly picks out phrases that are parts of prepositional phrases as well, but again, there are few enough of these that we can get away with it.)

The first step in this process is to add information about the verb to the `trackDF`. The following code adds two columns, `verbID` and `verbText`, to the `trackDF`, which tell us the chunk ID and text of the verb that the referential expression depends on (for example, in *I saw you*, the referential expressions *I* and *you* would contain information about *saw*). This process is a bit complicated; see `vignette("track")` for a more detailed explanation of what's going on.

```{r}
rez007 = rez007 %>%
  addFieldForeign("track", "default", "treeEntry", "default", "treeEntry", "treeParent", "parent", fieldaccess = "foreign")
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_left_join(rez007$chunkDF$verb %>% select(id, text, treeEntry),
                by = c(treeParent = "treeEntry"),
                suffix = c("", "_verb"),
                df2Address = "chunkDF/verb",
                fkey = "treeParent",
                df2key = "treeEntry",
                rezrObj = rez007) %>%
  rename(verbID = id_verb, verbText = text_verb)
rez007$trackDF$default %>% select(id, treeParent, verbID, verbText) %>% slice(1:20)
```

Here's the code for getting `verbText` from this:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>% rez_mutate(isPredOrFree = ((
  verbText %in% c("is", "was", "were", "are", "am", "'s", "'m", "'re") &
    is.na(Relation)
) | is.na(verbText)) %>% coalesce(F))
```

Now let's compare the character counts of referential expressions that are predicates or free, versus those that are not:

```{r}
rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew)) %>%
  ggplot(aes(x = isPredOrFree, y = charCount)) + geom_violin()
```

The tendency should now be clear, so let's add `isPredOrFree` to the model:

```{r}
pass3_model2 = rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew), charCount > 0) %>%
  lm(charCount ~ noCompetitors + noPrevMentionsIn10 + gapUnitsNew + Relation + isPredOrFree, .)
summary(pass3_model2)
```

Unfortunately, `isPredOrFree`  does not turn out to be a significant predictor.

### Splitting up `noPrevSubjMentions`
Let's see if we can improve upon the model in any more ways. The first thing we could do is to split up `noPrevMentionsIn10`. It is often proposed in the literature that subjects are more accessible than other types of arguments, and when the previous mention is a subject, the expression will subsequently be more accessible as well. So we could split up previous mentions into previous subjects and previous non-subjects.

The function `countPrevMentionsIf()` counts the number of times that a referent was mentioned previously in a specified window of units, along with the `TidyRez` function `rez_mutate()` (note that for non-subjects, we allow `Relation` to be `NA`):

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_mutate(noPrevSubjMentionsIn10 = countPrevMentionsIf(10, Relation == "Subj", exclFrag = T,
                                               nonFragmentMember = !str_detect(combinedChunk, "member")),
             noPrevNonSubjMentionsIn10 = countPrevMentionsIf(10, Relation != "Subj" | is.na(Relation), exclFrag = T,
                                               nonFragmentMember = !str_detect(combinedChunk, "member")))
rez007$trackDF$default %>% select(id, noPrevSubjMentionsIn10, noPrevNonSubjMentionsIn10)  %>% slice(1:20)
```
```{r}
pass3_model2 = rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew), charCount > 0) %>%
  lm(charCount ~ noCompetitors + noPrevSubjMentionsIn10 + noPrevNonSubjMentionsIn10 + gapUnitsNew + Relation + isPredOrFree, .)
summary(pass3_model2)
```

As we can now see, non-subjects have no effect at all, although the effect for subjects nears significance.

### Adding information about number

Let's take a final crack at the problem by seeing whether number (singular vs plural) has an effect on referential choice. Our steps are as follows:

1. We will first take a guess at what the number of a track in `rez007$trackDF` is using a set of simplistic rules based on the linguistic form.
2. Then we export a `.csv` file from `rezonateR`, and edit the automatic guesses in Microsoft Excel (or any other spreadsheet program of your choice).
3. We then import the `.csv` file back into `rezonateR` and update `rez007$trackDF` from the imported file.

Let's say we want to annotate the number of the referential expressions inside `trackDF$default`. A good approximation will be to mark everything that ends with \<s\> as plural, along with common plural pronouns and demonstratives, mark coordinate noun phrases as plural, mark noun phrases with singular demonstratives as singular, mark *you* as uncertain, and then mark the rest as singular:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>% rez_mutate(number = case_when(
  str_detect(text, " and ") ~ "pl",
  str_ends(text, "s") ~ "pl",
  str_detect(tolower(text), "(these|those)") ~ "pl",
  str_detect(tolower(text), "(this|that)") ~ "sg",
  tolower(text) %in% c("we", "they", "us", "them") ~ "pl",
  tolower(text) %in% c("you", "<0>") ~ "?",
  T ~ "sg"
))
head(rez007$trackDF$default %>% select(id, name, text, number))
```

Before we export this as a `.csv` for annotation, I would like to add a column inside the `trackDF` that gives us the transcription of the entire unit. It will be useful to be able to see this column while making manual annotations, such as when dealing with zero mentions. To simplify, we will just get the last unit even for multi-line chunks. Here is the code. We are using `rez_left_join()`, another TidyRez function, and extracting the `text` column of the unit whose `unitSeq` in `unitDF` corresponds to the `unitSeqLast` of a referential expression in `trackDF`:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  rez_left_join(rez007$unitDF %>% rez_select(unitSeq, text),
                by = c(unitSeqLast = "unitSeq"),
                suffix = c("", "_unit"),
                df2key = "unitSeq",
                rezrObj = rez007,
                df2Address = "unitDF",
                fkey = "unitSeqLast") %>%
  rez_rename(unitLastText = text_unit)
```

We then write the `csv` file. We only export a subset of the columns in the `trackDF` so that our screen is cleaner and easier to work with:

```{r}
rez_write_csv(rez007$trackDF$default, "rez007_refexpr.csv", c("id", "unitLastText", "tokenOrderLast", "text", "name", "number"))
```

An editing best practice is to copy the `.csv` file and edit from the copy, rather from the `.csv` you export directly. Figure 7 shows what the exported `.csv` looks like in Excel:

![Figure 7](img/sample-excel.PNG){width=100%}

After editing the CSV in a spreadsheet program, we import it back using `rez_read_csv()` (specifying the original `rezrDF` makes the import processes smoother and less error-prone):

```{r}
changeDF = rez_read_csv("rez007_refexpr_edited_sampleproj.csv", origDF = rez007$trackDF$default)
```

Finally, we use the `updateFromDF()` function to change the `number` column:

```{r}
rez007$trackDF$default = rez007$trackDF$default %>%
  updateFromDF(changeDF, changeCols = "number")
head(rez007$trackDF$default %>% select(id, text, number))
```
Now let's graph the difference between the singulars and plurals in a graph:

```{r}
rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew)) %>%
  ggplot(aes(x = number, y = charCount)) + geom_violin()
```

Singulars seem to be more concentrated towards the smaller character counts, but at the same time have more outliers that are very heavy. Let's put these in the model and see what happens:

```{r}
pass3_model3 = rez007$trackDF$default %>%
  filter(!is.na(gapUnitsNew), charCount > 0) %>%
  lm(charCount ~ noCompetitors + noPrevSubjMentionsIn10 + noPrevNonSubjMentionsIn10 + gapUnitsNew + number + Relation + isPredOrFree, .)
summary(pass3_model3)
```

Whether the current mention is a subject continues to turn out to be good predictors, and the noumber of previous subject mentions continues to be close to significance. The rest of the predictors are not significant, though some of them (particularly the number of competitors and lookback distance i.e. `gapUnits`) may hold some promise on a larger dataset. Grammatical number seems to be hopeless.

## Where to go from here?
This simple project shows most of the basic capabilities of `rezonateR`, though it still leaves out a lot, such as *reloads*, which allows you to update certain column automatically after changing other columns. `vignette("overview")` is a less topically focused overview of the package, less focused on a single problem but covering more topics. The series of tutorials starting from `vignette("import_save_basics")` is based on the same dataset as this tutorial, but covers most functionality of the package down to the smallest details, and you can pick and choose topics from there to read. Good luck!

